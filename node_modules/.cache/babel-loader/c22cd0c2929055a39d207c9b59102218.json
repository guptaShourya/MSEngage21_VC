{"ast":null,"code":"import _regeneratorRuntime from \"/Users/shouryagupta/Desktop/MS Engage 21/MSEngage21_VC/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport _asyncToGenerator from \"/Users/shouryagupta/Desktop/MS Engage 21/MSEngage21_VC/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _slicedToArray from \"/Users/shouryagupta/Desktop/MS Engage 21/MSEngage21_VC/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\nvar _jsxFileName = \"/Users/shouryagupta/Desktop/MS Engage 21/MSEngage21_VC/src/Participant.js\",\n    _s = $RefreshSig$();\n\nimport React, { useState, useEffect, useRef } from \"react\"; // import { GaussianBlurBackgroundProcessor } from '@twilio/video-processors';\n// const blurBackground = new GaussianBlurBackgroundProcessor({\n//   assetsPath: 'https://my-server-path/assets'\n// });\n\nconst Participant = ({\n  participant,\n  local\n}) => {\n  _s();\n\n  const _useState = useState([]),\n        _useState2 = _slicedToArray(_useState, 2),\n        videoTracks = _useState2[0],\n        setVideoTracks = _useState2[1];\n\n  const _useState3 = useState([]),\n        _useState4 = _slicedToArray(_useState3, 2),\n        audioTracks = _useState4[0],\n        setAudioTracks = _useState4[1];\n\n  const bodyPix = require('@tensorflow-models/body-pix');\n\n  function loadAndPredict(_x) {\n    return _loadAndPredict.apply(this, arguments);\n  }\n\n  function _loadAndPredict() {\n    _loadAndPredict = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(participant) {\n      var videoStream, net, segmentation, backgroundBlurAmount, edgeBlurAmount, flipHorizontal, canvas;\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) switch (_context.prev = _context.next) {\n          case 0:\n            videoStream = document.getElementById(participant.sid).firstChild;\n            _context.next = 3;\n            return bodyPix.load();\n\n          case 3:\n            net = _context.sent;\n            _context.next = 6;\n            return net.segmentPerson(videoStream);\n\n          case 6:\n            segmentation = _context.sent;\n            backgroundBlurAmount = 10;\n            edgeBlurAmount = 3;\n            flipHorizontal = false;\n            canvas = document.getElementById(participant.sid).firstChild; // Draw the image with the background blurred onto the canvas. The edge between\n            // the person and blurred background is blurred by 3 pixels.\n\n            bodyPix.drawBokehEffect(canvas, videoStream, segmentation, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);\n\n          case 12:\n          case \"end\":\n            return _context.stop();\n        }\n      }, _callee);\n    }));\n    return _loadAndPredict.apply(this, arguments);\n  }\n\n  const videoRef = useRef();\n  const audioRef = useRef();\n\n  const trackpubsToTracks = trackMap => Array.from(trackMap.values()).map(publication => publication.track).filter(track => track !== null);\n\n  useEffect(() => {\n    setVideoTracks(trackpubsToTracks(participant.videoTracks));\n    setAudioTracks(trackpubsToTracks(participant.audioTracks));\n\n    const trackSubscribed = track => {\n      if (track.kind === \"video\") {\n        setVideoTracks(videoTracks => [...videoTracks, track]);\n      } else if (track.kind === \"audio\") {\n        setAudioTracks(audioTracks => [...audioTracks, track]);\n      } else if (track.kind === 'data') {\n        track.on('message', data => {\n          const node = document.createElement('div');\n          let author = JSON.parse(data)['author'];\n          let message = JSON.parse(data)['data'];\n          const authorspan = document.createElement('span');\n          authorspan.style.fontWeight = 'bold';\n          const authornode = document.createTextNode(author + \": \");\n          authorspan.appendChild(authornode);\n          const textnode = document.createTextNode(message);\n          const textspan = document.createElement('span');\n          textspan.appendChild(textnode);\n          const wrapper = document.createElement('span');\n          wrapper.appendChild(authorspan);\n          wrapper.appendChild(textspan);\n          node.appendChild(wrapper);\n          document.getElementById('text-area').appendChild(node);\n        });\n      }\n    };\n\n    const trackUnsubscribed = track => {\n      if (track.kind === \"video\") {\n        setVideoTracks(videoTracks => videoTracks.filter(v => v !== track));\n      } else if (track.kind === \"audio\") {\n        setAudioTracks(audioTracks => audioTracks.filter(a => a !== track));\n      }\n    };\n\n    participant.on(\"trackSubscribed\", trackSubscribed);\n    participant.on(\"trackUnsubscribed\", trackUnsubscribed);\n    return () => {\n      setVideoTracks([]);\n      setAudioTracks([]);\n      participant.removeAllListeners();\n    };\n  }, [participant]);\n  useEffect(() => {\n    const videoTrack = videoTracks[0];\n\n    if (videoTrack) {\n      // blurBackground.loadModel().then(() => {\n      //     videoTrack.addProcessor(blurBackground);\n      // });\n      videoTrack.attach(videoRef.current);\n      loadAndPredict();\n      return () => {\n        videoTrack.detach();\n      };\n    }\n  }, [videoTracks]);\n  useEffect(() => {\n    const audioTrack = audioTracks[0];\n\n    if (audioTrack) {\n      audioTrack.attach(audioRef.current);\n      return () => {\n        audioTrack.detach();\n      };\n    }\n  }, [audioTracks]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"participant\",\n    id: participant.sid,\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      autoPlay: true\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 122,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"audio\", {\n      ref: audioRef,\n      autoPlay: true,\n      muted: false\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 123,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      className: \"overlayName\",\n      children: local ? \"You\" : participant.identity\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 124,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 121,\n    columnNumber: 5\n  }, this);\n};\n\n_s(Participant, \"mkU8c/5Desq4gBVgG4t6VGqYbcQ=\");\n\n_c = Participant;\nexport default Participant;\n\nvar _c;\n\n$RefreshReg$(_c, \"Participant\");","map":{"version":3,"sources":["/Users/shouryagupta/Desktop/MS Engage 21/MSEngage21_VC/src/Participant.js"],"names":["React","useState","useEffect","useRef","Participant","participant","local","videoTracks","setVideoTracks","audioTracks","setAudioTracks","bodyPix","require","loadAndPredict","videoStream","document","getElementById","sid","firstChild","load","net","segmentPerson","segmentation","backgroundBlurAmount","edgeBlurAmount","flipHorizontal","canvas","drawBokehEffect","videoRef","audioRef","trackpubsToTracks","trackMap","Array","from","values","map","publication","track","filter","trackSubscribed","kind","on","data","node","createElement","author","JSON","parse","message","authorspan","style","fontWeight","authornode","createTextNode","appendChild","textnode","textspan","wrapper","trackUnsubscribed","v","a","removeAllListeners","videoTrack","attach","current","detach","audioTrack","identity"],"mappings":";;;;;;;;AAAA,OAAOA,KAAP,IAAgBC,QAAhB,EAA0BC,SAA1B,EAAqCC,MAArC,QAAmD,OAAnD,C,CACA;AAEA;AACA;AACA;;AAEA,MAAMC,WAAW,GAAG,CAAC;AAAEC,EAAAA,WAAF;AAAeC,EAAAA;AAAf,CAAD,KAA4B;AAAA;;AAAA,oBACRL,QAAQ,CAAC,EAAD,CADA;AAAA;AAAA,QACvCM,WADuC;AAAA,QAC1BC,cAD0B;;AAAA,qBAERP,QAAQ,CAAC,EAAD,CAFA;AAAA;AAAA,QAEvCQ,WAFuC;AAAA,QAE1BC,cAF0B;;AAI9C,QAAMC,OAAO,GAAGC,OAAO,CAAC,6BAAD,CAAvB;;AAJ8C,WAMjCC,cANiC;AAAA;AAAA;;AAAA;AAAA,+EAMhD,iBAA8BR,WAA9B;AAAA;AAAA;AAAA;AAAA;AAEUS,YAAAA,WAFV,GAEwBC,QAAQ,CAACC,cAAT,CAAwBX,WAAW,CAACY,GAApC,EAAyCC,UAFjE;AAAA;AAAA,mBAGsBP,OAAO,CAACQ,IAAR,EAHtB;;AAAA;AAGUC,YAAAA,GAHV;AAAA;AAAA,mBAY+BA,GAAG,CAACC,aAAJ,CAAkBP,WAAlB,CAZ/B;;AAAA;AAYUQ,YAAAA,YAZV;AAcUC,YAAAA,oBAdV,GAciC,EAdjC;AAeUC,YAAAA,cAfV,GAe2B,CAf3B;AAgBUC,YAAAA,cAhBV,GAgB2B,KAhB3B;AAkBUC,YAAAA,MAlBV,GAkBmBX,QAAQ,CAACC,cAAT,CAAwBX,WAAW,CAACY,GAApC,EAAyCC,UAlB5D,EAmBI;AACA;;AACAP,YAAAA,OAAO,CAACgB,eAAR,CACID,MADJ,EACYZ,WADZ,EACyBQ,YADzB,EACuCC,oBADvC,EAEIC,cAFJ,EAEoBC,cAFpB;;AArBJ;AAAA;AAAA;AAAA;AAAA;AAAA,KANgD;AAAA;AAAA;;AAiC9C,QAAMG,QAAQ,GAAGzB,MAAM,EAAvB;AACA,QAAM0B,QAAQ,GAAG1B,MAAM,EAAvB;;AAEA,QAAM2B,iBAAiB,GAAIC,QAAD,IACxBC,KAAK,CAACC,IAAN,CAAWF,QAAQ,CAACG,MAAT,EAAX,EACGC,GADH,CACQC,WAAD,IAAiBA,WAAW,CAACC,KADpC,EAEGC,MAFH,CAEWD,KAAD,IAAWA,KAAK,KAAK,IAF/B,CADF;;AAKAnC,EAAAA,SAAS,CAAC,MAAM;AACdM,IAAAA,cAAc,CAACsB,iBAAiB,CAACzB,WAAW,CAACE,WAAb,CAAlB,CAAd;AACAG,IAAAA,cAAc,CAACoB,iBAAiB,CAACzB,WAAW,CAACI,WAAb,CAAlB,CAAd;;AAEA,UAAM8B,eAAe,GAAIF,KAAD,IAAW;AACjC,UAAIA,KAAK,CAACG,IAAN,KAAe,OAAnB,EAA4B;AAC1BhC,QAAAA,cAAc,CAAED,WAAD,IAAiB,CAAC,GAAGA,WAAJ,EAAiB8B,KAAjB,CAAlB,CAAd;AACD,OAFD,MAEO,IAAIA,KAAK,CAACG,IAAN,KAAe,OAAnB,EAA4B;AACjC9B,QAAAA,cAAc,CAAED,WAAD,IAAiB,CAAC,GAAGA,WAAJ,EAAiB4B,KAAjB,CAAlB,CAAd;AACD,OAFM,MAEA,IAAIA,KAAK,CAACG,IAAN,KAAe,MAAnB,EAA0B;AAC7BH,QAAAA,KAAK,CAACI,EAAN,CAAS,SAAT,EAAoBC,IAAI,IAAI;AAC1B,gBAAMC,IAAI,GAAG5B,QAAQ,CAAC6B,aAAT,CAAuB,KAAvB,CAAb;AACA,cAAIC,MAAM,GAAGC,IAAI,CAACC,KAAL,CAAWL,IAAX,EAAiB,QAAjB,CAAb;AACA,cAAIM,OAAO,GAAGF,IAAI,CAACC,KAAL,CAAWL,IAAX,EAAiB,MAAjB,CAAd;AACA,gBAAMO,UAAU,GAAGlC,QAAQ,CAAC6B,aAAT,CAAuB,MAAvB,CAAnB;AACAK,UAAAA,UAAU,CAACC,KAAX,CAAiBC,UAAjB,GAA8B,MAA9B;AACA,gBAAMC,UAAU,GAAGrC,QAAQ,CAACsC,cAAT,CAAwBR,MAAM,GAAG,IAAjC,CAAnB;AACAI,UAAAA,UAAU,CAACK,WAAX,CAAuBF,UAAvB;AACA,gBAAMG,QAAQ,GAAGxC,QAAQ,CAACsC,cAAT,CAAwBL,OAAxB,CAAjB;AACA,gBAAMQ,QAAQ,GAAGzC,QAAQ,CAAC6B,aAAT,CAAuB,MAAvB,CAAjB;AACAY,UAAAA,QAAQ,CAACF,WAAT,CAAqBC,QAArB;AACA,gBAAME,OAAO,GAAG1C,QAAQ,CAAC6B,aAAT,CAAuB,MAAvB,CAAhB;AACAa,UAAAA,OAAO,CAACH,WAAR,CAAoBL,UAApB;AACAQ,UAAAA,OAAO,CAACH,WAAR,CAAoBE,QAApB;AACAb,UAAAA,IAAI,CAACW,WAAL,CAAiBG,OAAjB;AACA1C,UAAAA,QAAQ,CAACC,cAAT,CAAwB,WAAxB,EAAqCsC,WAArC,CAAiDX,IAAjD;AACH,SAhBC;AAiBH;AACF,KAxBD;;AA0BA,UAAMe,iBAAiB,GAAIrB,KAAD,IAAW;AACnC,UAAIA,KAAK,CAACG,IAAN,KAAe,OAAnB,EAA4B;AAC1BhC,QAAAA,cAAc,CAAED,WAAD,IAAiBA,WAAW,CAAC+B,MAAZ,CAAoBqB,CAAD,IAAOA,CAAC,KAAKtB,KAAhC,CAAlB,CAAd;AACD,OAFD,MAEO,IAAIA,KAAK,CAACG,IAAN,KAAe,OAAnB,EAA4B;AACjC9B,QAAAA,cAAc,CAAED,WAAD,IAAiBA,WAAW,CAAC6B,MAAZ,CAAoBsB,CAAD,IAAOA,CAAC,KAAKvB,KAAhC,CAAlB,CAAd;AACD;AACF,KAND;;AAQAhC,IAAAA,WAAW,CAACoC,EAAZ,CAAe,iBAAf,EAAkCF,eAAlC;AACAlC,IAAAA,WAAW,CAACoC,EAAZ,CAAe,mBAAf,EAAoCiB,iBAApC;AAEA,WAAO,MAAM;AACXlD,MAAAA,cAAc,CAAC,EAAD,CAAd;AACAE,MAAAA,cAAc,CAAC,EAAD,CAAd;AACAL,MAAAA,WAAW,CAACwD,kBAAZ;AACD,KAJD;AAKD,GA9CQ,EA8CN,CAACxD,WAAD,CA9CM,CAAT;AAgDAH,EAAAA,SAAS,CAAC,MAAM;AACd,UAAM4D,UAAU,GAAGvD,WAAW,CAAC,CAAD,CAA9B;;AACA,QAAIuD,UAAJ,EAAgB;AACd;AACA;AACA;AACAA,MAAAA,UAAU,CAACC,MAAX,CAAkBnC,QAAQ,CAACoC,OAA3B;AACAnD,MAAAA,cAAc;AACd,aAAO,MAAM;AACXiD,QAAAA,UAAU,CAACG,MAAX;AACD,OAFD;AAGD;AACF,GAZQ,EAYN,CAAC1D,WAAD,CAZM,CAAT;AAcAL,EAAAA,SAAS,CAAC,MAAM;AACd,UAAMgE,UAAU,GAAGzD,WAAW,CAAC,CAAD,CAA9B;;AACA,QAAIyD,UAAJ,EAAgB;AACdA,MAAAA,UAAU,CAACH,MAAX,CAAkBlC,QAAQ,CAACmC,OAA3B;AACA,aAAO,MAAM;AACXE,QAAAA,UAAU,CAACD,MAAX;AACD,OAFD;AAGD;AACF,GARQ,EAQN,CAACxD,WAAD,CARM,CAAT;AASA,sBACE;AAAK,IAAA,SAAS,EAAC,aAAf;AAA6B,IAAA,EAAE,EAAGJ,WAAW,CAACY,GAA9C;AAAA,4BACE;AAAO,MAAA,GAAG,EAAEW,QAAZ;AAAsB,MAAA,QAAQ,EAAE;AAAhC;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAO,MAAA,GAAG,EAAEC,QAAZ;AAAsB,MAAA,QAAQ,EAAE,IAAhC;AAAsC,MAAA,KAAK,EAAE;AAA7C;AAAA;AAAA;AAAA;AAAA,YAFF,eAGE;AAAG,MAAA,SAAS,EAAG,aAAf;AAAA,gBAA8BvB,KAAK,GAAC,KAAD,GAAOD,WAAW,CAAC8D;AAAtD;AAAA;AAAA;AAAA;AAAA,YAHF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAOD,CAvHD;;GAAM/D,W;;KAAAA,W;AAyHN,eAAeA,WAAf","sourcesContent":["import React, { useState, useEffect, useRef } from \"react\";\n// import { GaussianBlurBackgroundProcessor } from '@twilio/video-processors';\n\n// const blurBackground = new GaussianBlurBackgroundProcessor({\n//   assetsPath: 'https://my-server-path/assets'\n// });\n\nconst Participant = ({ participant, local }) => {\n  const [videoTracks, setVideoTracks] = useState([]);\n  const [audioTracks, setAudioTracks] = useState([]);\n  \n  const bodyPix = require('@tensorflow-models/body-pix');\n\nasync function loadAndPredict(participant) {\n\n    const videoStream = document.getElementById(participant.sid).firstChild;\n    const net = await bodyPix.load(/** optional arguments, see below **/);\n    /**\n     * One of (see documentation below):\n     *   - net.segmentPerson\n     *   - net.segmentPersonParts\n     *   - net.segmentMultiPerson\n     *   - net.segmentMultiPersonParts\n     * See documentation below for details on each method.\n        */\n    const segmentation = await net.segmentPerson(videoStream);\n\n    const backgroundBlurAmount = 10;\n    const edgeBlurAmount = 3;\n    const flipHorizontal = false;\n\n    const canvas = document.getElementById(participant.sid).firstChild;\n    // Draw the image with the background blurred onto the canvas. The edge between\n    // the person and blurred background is blurred by 3 pixels.\n    bodyPix.drawBokehEffect(\n        canvas, videoStream, segmentation, backgroundBlurAmount,\n        edgeBlurAmount, flipHorizontal);\n}\n\n\n  const videoRef = useRef();\n  const audioRef = useRef();\n\n  const trackpubsToTracks = (trackMap) =>\n    Array.from(trackMap.values())\n      .map((publication) => publication.track)\n      .filter((track) => track !== null);\n\n  useEffect(() => {\n    setVideoTracks(trackpubsToTracks(participant.videoTracks));\n    setAudioTracks(trackpubsToTracks(participant.audioTracks));\n\n    const trackSubscribed = (track) => {\n      if (track.kind === \"video\") {\n        setVideoTracks((videoTracks) => [...videoTracks, track]);\n      } else if (track.kind === \"audio\") {\n        setAudioTracks((audioTracks) => [...audioTracks, track]);\n      } else if (track.kind === 'data'){\n          track.on('message', data => {\n            const node = document.createElement('div');\n            let author = JSON.parse(data)['author'];\n            let message = JSON.parse(data)['data'];\n            const authorspan = document.createElement('span');\n            authorspan.style.fontWeight = 'bold';\n            const authornode = document.createTextNode(author + \": \");\n            authorspan.appendChild(authornode);\n            const textnode = document.createTextNode(message);\n            const textspan = document.createElement('span');\n            textspan.appendChild(textnode);\n            const wrapper = document.createElement('span');\n            wrapper.appendChild(authorspan);\n            wrapper.appendChild(textspan);\n            node.appendChild(wrapper);\n            document.getElementById('text-area').appendChild(node);\n        });\n      }\n    };\n\n    const trackUnsubscribed = (track) => {\n      if (track.kind === \"video\") {\n        setVideoTracks((videoTracks) => videoTracks.filter((v) => v !== track));\n      } else if (track.kind === \"audio\") {\n        setAudioTracks((audioTracks) => audioTracks.filter((a) => a !== track));\n      } \n    };\n\n    participant.on(\"trackSubscribed\", trackSubscribed);\n    participant.on(\"trackUnsubscribed\", trackUnsubscribed);\n\n    return () => {\n      setVideoTracks([]);\n      setAudioTracks([]);\n      participant.removeAllListeners();\n    };\n  }, [participant]);\n  \n  useEffect(() => {\n    const videoTrack = videoTracks[0];\n    if (videoTrack) {\n      // blurBackground.loadModel().then(() => {\n      //     videoTrack.addProcessor(blurBackground);\n      // });\n      videoTrack.attach(videoRef.current);\n      loadAndPredict();\n      return () => {\n        videoTrack.detach();\n      };\n    }\n  }, [videoTracks]);\n\n  useEffect(() => {\n    const audioTrack = audioTracks[0];\n    if (audioTrack) {\n      audioTrack.attach(audioRef.current);\n      return () => {\n        audioTrack.detach();\n      };\n    }\n  }, [audioTracks]);\n  return (\n    <div className=\"participant\" id ={participant.sid}>\n      <video ref={videoRef} autoPlay={true}/>\n      <audio ref={audioRef} autoPlay={true} muted={false} />\n      <p className = 'overlayName'>{local?\"You\":participant.identity}</p>\n    </div>\n  );\n};\n\nexport default Participant;\n"]},"metadata":{},"sourceType":"module"}