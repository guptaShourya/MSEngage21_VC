{"ast":null,"code":"import _slicedToArray from \"/Users/shouryagupta/Desktop/MS Engage 21/MSEngage21_VC/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util } from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport { assertNotComplex } from '../cpu_util';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl } from './Transpose_impl';\nexport function max(args) {\n  const inputs = args.inputs,\n        backend = args.backend,\n        attrs = args.attrs;\n  const x = inputs.x;\n  const reductionIndices = attrs.reductionIndices,\n        keepDims = attrs.keepDims;\n  const cpuBackend = backend;\n  let xShape = x.shape;\n  const xRank = xShape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, xShape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  let xVals = cpuBackend.data.get(x.dataId).values;\n\n  if (permutedAxes != null) {\n    const newShape = new Array(xRank);\n\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = xShape[permutedAxes[i]];\n    }\n\n    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    xShape = newShape;\n  }\n\n  assertNotComplex(x, 'max');\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n\n  const _backend_util$compute = backend_util.computeOutAndReduceShapes(xShape, axes),\n        _backend_util$compute2 = _slicedToArray(_backend_util$compute, 2),\n        maxOutShape = _backend_util$compute2[0],\n        reduceShape = _backend_util$compute2[1];\n\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n  let outShape = maxOutShape;\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    outShape = newShape;\n  }\n\n  return {\n    dataId,\n    shape: outShape,\n    dtype: x.dtype\n  };\n}\nexport const maxConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: max\n};","map":{"version":3,"sources":["../../src/kernels/Max.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAoB,GAApB,QAA+D,uBAA/D;AACA,SAAQ,YAAR,QAAyC,uBAAzC;AACA,SAAoB,IAApB,QAA+B,uBAA/B;AAGA,SAAQ,gBAAR,QAA+B,aAA/B;AAEA,SAAQ,OAAR,QAAsB,YAAtB;AACA,SAAQ,aAAR,QAA4B,kBAA5B;AAEA,OAAM,SAAU,GAAV,CACF,IADE,EACiE;AAAA,QAE9D,MAF8D,GAEpC,IAFoC,CAE9D,MAF8D;AAAA,QAEtD,OAFsD,GAEpC,IAFoC,CAEtD,OAFsD;AAAA,QAE7C,KAF6C,GAEpC,IAFoC,CAE7C,KAF6C;AAAA,QAG9D,CAH8D,GAGzD,MAHyD,CAG9D,CAH8D;AAAA,QAI9D,gBAJ8D,GAIhC,KAJgC,CAI9D,gBAJ8D;AAAA,QAI5C,QAJ4C,GAIhC,KAJgC,CAI5C,QAJ4C;AAKrE,QAAM,UAAU,GAAG,OAAnB;AACA,MAAI,MAAM,GAAG,CAAC,CAAC,KAAf;AACA,QAAM,KAAK,GAAG,MAAM,CAAC,MAArB;AAEA,QAAM,QAAQ,GAAG,IAAI,CAAC,cAAL,CAAoB,gBAApB,EAAsC,MAAtC,CAAjB;AACA,MAAI,IAAI,GAAG,QAAX;AACA,QAAM,YAAY,GAAG,YAAY,CAAC,kBAAb,CAAgC,IAAhC,EAAsC,KAAtC,CAArB;AACA,MAAI,KAAK,GAAG,UAAU,CAAC,IAAX,CAAgB,GAAhB,CAAoB,CAAC,CAAC,MAAtB,EAA8B,MAA1C;;AACA,MAAI,YAAY,IAAI,IAApB,EAA0B;AACxB,UAAM,QAAQ,GAAa,IAAI,KAAJ,CAAU,KAAV,CAA3B;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,QAAQ,CAAC,MAA7B,EAAqC,CAAC,EAAtC,EAA0C;AACxC,MAAA,QAAQ,CAAC,CAAD,CAAR,GAAc,MAAM,CAAC,YAAY,CAAC,CAAD,CAAb,CAApB;AACD;;AAED,IAAA,KAAK,GAAG,aAAa,CAAC,KAAD,EAAQ,MAAR,EAAgB,CAAC,CAAC,KAAlB,EAAyB,YAAzB,EAAuC,QAAvC,CAArB;AACA,IAAA,IAAI,GAAG,YAAY,CAAC,gBAAb,CAA8B,IAAI,CAAC,MAAnC,EAA2C,KAA3C,CAAP;AAEA,IAAA,MAAM,GAAG,QAAT;AACD;;AAED,EAAA,gBAAgB,CAAC,CAAD,EAAI,KAAJ,CAAhB;AACA,EAAA,YAAY,CAAC,0BAAb,CAAwC,KAAxC,EAA+C,IAA/C,EAAqD,KAArD;;AA1BqE,gCA4BjE,YAAY,CAAC,yBAAb,CAAuC,MAAvC,EAA+C,IAA/C,CA5BiE;AAAA;AAAA,QA2B9D,WA3B8D;AAAA,QA2BjD,WA3BiD;;AA8BrE,QAAM,UAAU,GAAG,IAAI,CAAC,aAAL,CAAmB,WAAnB,CAAnB;AAEA,QAAM,MAAM,GAAG,OAAO,CAAC,KAAD,EAAQ,UAAR,EAAoB,WAApB,EAAiC,CAAC,CAAC,KAAnC,CAAtB;AACA,QAAM,MAAM,GAAG,UAAU,CAAC,KAAX,CAAiB,MAAjB,EAAyB,WAAzB,EAAsC,CAAC,CAAC,KAAxC,CAAf;AAEA,MAAI,QAAQ,GAAG,WAAf;;AACA,MAAI,QAAJ,EAAc;AACZ;AACA,UAAM,QAAQ,GAAG,YAAY,CAAC,oBAAb,CAAkC,WAAlC,EAA+C,QAA/C,CAAjB;AACA,IAAA,QAAQ,GAAG,QAAX;AACD;;AAED,SAAO;AAAC,IAAA,MAAD;AAAS,IAAA,KAAK,EAAE,QAAhB;AAA0B,IAAA,KAAK,EAAE,CAAC,CAAC;AAAnC,GAAP;AACD;AAED,OAAO,MAAM,SAAS,GAAiB;AACrC,EAAA,UAAU,EAAE,GADyB;AAErC,EAAA,WAAW,EAAE,KAFwB;AAGrC,EAAA,UAAU,EAAE;AAHyB,CAAhC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: MathBackendCPU, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n  const cpuBackend = backend;\n  let xShape = x.shape;\n  const xRank = xShape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, xShape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n  if (permutedAxes != null) {\n    const newShape: number[] = new Array(xRank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = xShape[permutedAxes[i]];\n    }\n\n    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n    xShape = newShape;\n  }\n\n  assertNotComplex(x, 'max');\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, axes);\n\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    outShape = newShape;\n  }\n\n  return {dataId, shape: outShape, dtype: x.dtype};\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: max as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}