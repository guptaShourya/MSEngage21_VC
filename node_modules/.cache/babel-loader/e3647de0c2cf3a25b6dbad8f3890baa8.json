{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nexport class DepthwiseConvPacked2DProgram {\n  constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false, hasLeakyReluAlpha = false) {\n    this.variableNames = ['x', 'W'];\n    this.packedInputs = true;\n    this.packedOutput = true;\n    this.outputShape = convInfo.outShape;\n    const channelMul = convInfo.outChannels / convInfo.inChannels;\n    const xNumRows = convInfo.inHeight;\n    const xNumCols = convInfo.inWidth;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const texelsAcross = filterWidth;\n    let mainLoop = \"\\n      int xR; int xC; int xCOffset;\\n      vec4 wTexel; vec4 previous; vec4 final;\";\n\n    for (let c = 0; c < filterWidth; c++) {\n      mainLoop += \"\\n          vec4 xTexelC\".concat(c * 2, \";\\n          int xTexelC\").concat(c * 2, \"Ready;\\n          vec4 xC\").concat(c, \";\");\n    }\n    /**\n     * This vectorized implementation works by gathering the values needed for\n     * each output channel's dot product into vec4's and then multiplying them\n     * all together (this happens in the final double for-loop below). Most of\n     * the main loop consists of constructing these vec4's with the minimum\n     * number of texture2D calls, which means making use of all four returned\n     * values from a texture2D call at once.\n     */\n\n\n    for (let r = 0; r < filterHeight; r++) {\n      for (let c = 0; c < filterWidth; c++) {\n        mainLoop += \"\\n          xTexelC\".concat(c * 2, \" = vec4(0.0);\\n          xTexelC\").concat(c * 2, \"Ready = 0;\\n          xC\").concat(c, \" = vec4(0.0);\");\n      }\n\n      mainLoop += \"\\n        xR = xRCorner + \".concat(r * dilationHeight, \";\\n        if (xR >=0 && xR < \").concat(xNumRows, \") {\\n      \");\n\n      for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n        const colIndex = texelC * 2;\n        const c = colIndex * dilationWidth;\n        mainLoop += \"\\n          xC = xCCorner + \".concat(c, \";\\n          \");\n\n        if (strideWidth === 1) {\n          if (colIndex < filterWidth) {\n            // If padding is odd, the outer texels have to be composed.\n            if (padLeft % 2 === 1) {\n              // TODO: Ensure vec4 previous does not result in redundant sample,\n              // and avoid setting xTexelRC's that exceed the boundary in the\n              // first place rather than resetting them to vec4(0)).\n              // To compute xCOffset:\n              // - If padding is odd, we must add 1 to ensure we ask for an\n              // even-numbered row.\n              // - We subtract 2 to access the previous texel.\n              mainLoop += \"\\n                xCOffset = xC + 1;\\n                if (xCOffset >= 0 && xCOffset < \".concat(xNumCols, \" && xTexelC\").concat(c, \"Ready == 0) {\\n                  xTexelC\").concat(c, \" = getX(batch, xR, xCOffset, d1);\\n\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(c, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(c, \"Ready = 1;\\n                }\\n              \"); // This texel has been read in previous iteration if the dilation\n              // is 1.\n\n              if (dilationWidth === 1 && c > 0) {\n                mainLoop += \"\\n                xC\".concat(colIndex, \" = vec4(xTexelC\").concat(c - 2, \".zw, xTexelC\").concat(c, \".xy);\\n                \");\n              } else {\n                mainLoop += \"\\n                  xCOffset = xC + 1 - 2;\\n\\n                  if (xCOffset >= 0 && xCOffset < \".concat(xNumCols, \") {\\n                    previous = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                      previous.zw = vec2(0.0);\\n                    }\\n\\n                    xC\").concat(colIndex, \" = vec4(previous.zw, xTexelC\").concat(c, \".xy);\\n                  } else {\\n                    xC\").concat(colIndex, \" = vec4(0.0, 0.0, xTexelC\").concat(c, \".xy);\\n                  }\\n                  \");\n              }\n            } else {\n              // Padding is even, so xRC corresponds to a single texel.\n              mainLoop += \"\\n                if (xC >= 0 && xC < \".concat(xNumCols, \" && xTexelC\").concat(c, \"Ready == 0) {\\n                  xTexelC\").concat(c, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(c, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(c, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = xTexelC\").concat(c, \";\\n                \");\n            }\n\n            if (c + 1 < filterWidth) {\n              // If dilation is even, the second entry should match the first\n              // (either both are composed or both are single samples). But if\n              // dilation is odd, then the second entry should be the opposite\n              // of the first (if the first is composed, the second is a single\n              // sample, and vice versa.)\n              const nextTexelOffset = padLeft % 2 === 0 ? util.nearestLargerEven(dilationWidth) : dilationWidth;\n\n              if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {\n                mainLoop += \"\\n                  xCOffset = xC + \".concat(padLeft % 2, \" + \").concat(nextTexelOffset, \";\\n\\n                  if (xCOffset >= 0 && xCOffset < \").concat(xNumCols, \" && xTexelC\").concat(c + 2, \"Ready == 0) {\\n                    xTexelC\").concat(c + 2, \" = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                      xTexelC\").concat(c + 2, \".zw = vec2(0.0);\\n                    }\\n                    xTexelC\").concat(c + 2, \"Ready = 1;\\n                  }\\n                  \"); // If dilation > 1 then the xRC's will not be able to share any\n                // values, so each xRC will require two unique calls to getX.\n\n                if (dilationWidth > 1) {\n                  mainLoop += \"\\n                    xCOffset -= 2;\\n                    if (xCOffset >= 0 && xCOffset < \".concat(xNumCols, \" && xTexelC\").concat(c, \"Ready == 0) {\\n                      xTexelC\").concat(c, \" = getX(batch, xR, xCOffset, d1);\\n                      xTexelC\").concat(c, \"Ready = 1;\\n                    }\\n                    \");\n                }\n\n                mainLoop += \"\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(c, \".zw, xTexelC\").concat(c + 2, \".xy);\\n                  \");\n              } else {\n                // If dilation is 1 and padding is odd, we have already read the\n                // texel when constructing the previous x value. Here we can\n                // simply skip the texture read.\n                if (nextTexelOffset === 1) {\n                  mainLoop += \"\\n                    xC\".concat(colIndex + 1, \" = xTexelC\").concat(c, \";\\n                    \");\n                } else {\n                  mainLoop += \"\\n                    xCOffset = xC + \".concat(nextTexelOffset, \";\\n\\n                    if (xCOffset >= 0 && xCOffset < \").concat(xNumCols, \" && xTexelC\").concat(c + 2, \"Ready == 0) {\\n                      xTexelC\").concat(c + 2, \" = getX(batch, xR, xCOffset, d1);\\n                      if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                        xTexelC\").concat(c + 2, \".zw = vec2(0.0);\\n                      }\\n                      xTexelC\").concat(c + 2, \"Ready = 1;\\n                    }\\n\\n                    xC\").concat(colIndex + 1, \" = xTexelC\").concat(c + 2, \";\\n                    \");\n                }\n              }\n            }\n          }\n        } else {\n          // stride === 2\n          if (c < filterWidth) {\n            // Depending on whether padLeft is even or odd, we want either the\n            // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n            // even, xC${colIndex +1} is simply the zw channels of texels we've\n            // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n            // need to come from the xy channels of a new texel, hence the `\n            // vec4\n            // final` initialized below.\n            if (padLeft % 2 === 1) {\n              mainLoop += \"\\n                xCOffset = xC + 1 - \".concat(strideWidth, \";\\n                if(xCOffset >= 0 && xCOffset < \").concat(xNumCols, \" && xTexelC\").concat(c, \"Ready == 0) {\\n                  xTexelC\").concat(c, \" = getX(batch, xR, xCOffset, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(c, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(c, \"Ready = 1;\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < \").concat(xNumCols, \" && xTexelC\").concat(c + 2, \"Ready == 0) {\\n                  xTexelC\").concat(c + 2, \" = getX(batch, xR, xC + 1, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xC + 2 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(c + 2, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(c + 2, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = vec4(xTexelC\").concat(c, \".zw, xTexelC\").concat(c + 2, \".zw);\\n              \");\n\n              if (c + 1 < filterWidth) {\n                mainLoop += \"\\n                  final = vec4(0.0);\\n                  xCOffset = xC + 1 + \".concat(strideWidth, \";\\n                  if(xCOffset >= 0 && xCOffset < \").concat(xNumCols, \") {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xC\").concat(colIndex + 1, \" = vec4(xTexelC\").concat(c + 2, \".xy, final.xy);\\n                \");\n              }\n            } else {\n              mainLoop += \"\\n                if(xC >= 0 && xC < \".concat(xNumCols, \" && xTexelC\").concat(c, \"Ready == 0) {\\n                  xTexelC\").concat(c, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(c, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(c, \"Ready = 1;\\n                }\\n\\n                xCOffset = xC + \").concat(strideWidth, \";\\n                if(xCOffset >= 0 && xCOffset < \").concat(xNumCols, \" && xTexelC\").concat(c + 2, \"Ready == 0) {\\n                  xTexelC\").concat(c + 2, \" = getX(batch, xR, xCOffset, d1);\\n                  if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(c + 2, \".zw = vec2(0.);\\n                  }\\n                  xTexelC\").concat(c + 2, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = vec4(\\n                  xTexelC\").concat(c, \".xy, xTexelC\").concat(c + 2, \".xy);\\n              \");\n\n              if (c + 1 < filterWidth) {\n                mainLoop += \"\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(c, \".zw, xTexelC\").concat(c + 2, \".zw);\\n                \");\n              }\n            }\n          }\n        } // localize the dotProd accumulation within the loop, the theory is for\n        // GPU with limited cache, accumulate sum across large amount of\n        // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n        // 50 variables)\n\n\n        if (colIndex < filterWidth) {\n          mainLoop += \"\\n            wTexel = getW(\".concat(r, \", \").concat(c, \", d1, q);\\n            dotProd += xC\").concat(colIndex, \" * vec4(wTexel.xz, wTexel.xz);\\n          \");\n\n          if (c + 1 < filterWidth) {\n            mainLoop += \"\\n              wTexel = getW(\".concat(r, \", \").concat(c + 1, \", d1, q);\\n              dotProd += xC\").concat(colIndex + 1, \" * vec4(wTexel.xz, wTexel.xz);\\n            \");\n          }\n        }\n      }\n\n      mainLoop += \"\\n        }\\n      \";\n    }\n\n    let activationSnippet = '',\n        applyActivationSnippet = '';\n\n    if (activation) {\n      if (hasPreluActivation) {\n        activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(activation, \"\\n        }\");\n      } else if (hasLeakyReluAlpha) {\n        activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(activation, \"\\n        }\");\n      } else {\n        activationSnippet = \"vec4 activation(vec4 x) {\\n          \".concat(activation, \"\\n        }\");\n      }\n\n      applyActivationSnippet = \"result = activation(result);\";\n    }\n\n    const addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    if (hasLeakyReluAlpha) {\n      this.variableNames.push('leakyreluAlpha');\n    }\n\n    this.userCode = \"\\n      \".concat(activationSnippet, \"\\n\\n      const ivec2 strides = ivec2(\").concat(strideHeight, \", \").concat(strideWidth, \");\\n      const ivec2 pads = ivec2(\").concat(padTop, \", \").concat(padLeft, \");\\n\\n      void main() {\\n\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \").concat(channelMul, \";\\n        int q = d2 - d1 * \").concat(channelMul, \";\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\\n        vec4 dotProd = vec4(0.000000000000001);\\n\\n        \").concat(mainLoop, \"\\n\\n        vec4 result = dotProd - vec4(0.000000000000001);\\n        \").concat(addBiasSnippet, \"\\n        \").concat(applyActivationSnippet, \"\\n        setOutput(result);\\n      }\\n    \");\n  }\n\n}","map":{"version":3,"sources":["../src/conv_packed_gpu_depthwise.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAsB,IAAtB,QAAiC,uBAAjC;AAIA,OAAM,MAAO,4BAAP,CAAmC;AAOvC,EAAA,WAAA,CACI,QADJ,EACuC,OAAO,GAAG,KADjD,EAEI,UAAA,GAAqB,IAFzB,EAE+B,kBAAkB,GAAG,KAFpD,EAGI,iBAAiB,GAAG,KAHxB,EAG6B;AAT7B,SAAA,aAAA,GAAgB,CAAC,GAAD,EAAM,GAAN,CAAhB;AACA,SAAA,YAAA,GAAe,IAAf;AACA,SAAA,YAAA,GAAe,IAAf;AAQE,SAAK,WAAL,GAAmB,QAAQ,CAAC,QAA5B;AACA,UAAM,UAAU,GAAG,QAAQ,CAAC,WAAT,GAAuB,QAAQ,CAAC,UAAnD;AACA,UAAM,QAAQ,GAAG,QAAQ,CAAC,QAA1B;AACA,UAAM,QAAQ,GAAG,QAAQ,CAAC,OAA1B;AACA,UAAM,MAAM,GAAG,QAAQ,CAAC,OAAT,CAAiB,GAAhC;AACA,UAAM,OAAO,GAAG,QAAQ,CAAC,OAAT,CAAiB,IAAjC;AACA,UAAM,YAAY,GAAG,QAAQ,CAAC,YAA9B;AACA,UAAM,WAAW,GAAG,QAAQ,CAAC,WAA7B;AACA,UAAM,cAAc,GAAG,QAAQ,CAAC,cAAhC;AACA,UAAM,aAAa,GAAG,QAAQ,CAAC,aAA/B;AACA,UAAM,YAAY,GAAG,QAAQ,CAAC,YAA9B;AACA,UAAM,WAAW,GAAG,QAAQ,CAAC,WAA7B;AACA,UAAM,YAAY,GAAG,WAArB;AAEA,QAAI,QAAQ,yFAAZ;;AAIA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,WAApB,EAAiC,CAAC,EAAlC,EAAsC;AACpC,MAAA,QAAQ,sCACU,CAAC,GAAG,CADd,qCAES,CAAC,GAAG,CAFb,sCAGK,CAHL,MAAR;AAID;AAED;;;;;;;AAOG;;;AACH,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,YAApB,EAAkC,CAAC,EAAnC,EAAuC;AACrC,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,WAApB,EAAiC,CAAC,EAAlC,EAAsC;AACpC,QAAA,QAAQ,iCACG,CAAC,GAAG,CADP,6CAEG,CAAC,GAAG,CAFP,qCAGF,CAHE,kBAAR;AAID;;AACD,MAAA,QAAQ,wCACY,CAAC,GAAG,cADhB,2CAEe,QAFf,gBAAR;;AAKA,WAAK,IAAI,MAAM,GAAG,CAAlB,EAAqB,MAAM,GAAG,CAAC,YAAY,GAAG,CAAhB,IAAqB,CAAnD,EAAsD,MAAM,EAA5D,EAAgE;AAC9D,cAAM,QAAQ,GAAG,MAAM,GAAG,CAA1B;AACA,cAAM,CAAC,GAAG,QAAQ,GAAG,aAArB;AAEA,QAAA,QAAQ,0CACY,CADZ,kBAAR;;AAIA,YAAI,WAAW,KAAK,CAApB,EAAuB;AACrB,cAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B;AACA,gBAAI,OAAO,GAAG,CAAV,KAAgB,CAApB,EAAuB;AACrB;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA,cAAA,QAAQ,oGAE4B,QAF5B,wBAGJ,CAHI,qDAIK,CAJL,wNAQkB,QARlB,6CASO,CATP,6EAWK,CAXL,kDAAR,CAVqB,CAwBrB;AACA;;AACA,kBAAI,aAAa,KAAK,CAAlB,IAAuB,CAAC,GAAG,CAA/B,EAAkC;AAChC,gBAAA,QAAQ,kCACJ,QADI,4BACsB,CAAC,GAAG,CAD1B,yBAC0C,CAD1C,4BAAR;AAGD,eAJD,MAIO;AACL,gBAAA,QAAQ,8GAG4B,QAH5B,+PAQkB,QARlB,iHAYA,QAZA,yCAYuC,CAZvC,sEAcA,QAdA,sCAcoC,CAdpC,mDAAR;AAiBD;AACF,aAjDD,MAiDO;AACL;AACA,cAAA,QAAQ,oDACgB,QADhB,wBACsC,CADtC,qDAEK,CAFL,0EAGY,QAHZ,6CAIO,CAJP,6EAMK,CANL,gEASF,QATE,uBASmB,CATnB,wBAAR;AAWD;;AAED,gBAAI,CAAC,GAAG,CAAJ,GAAQ,WAAZ,EAAyB;AACvB;AACA;AACA;AACA;AACA;AAEA,oBAAM,eAAe,GAAG,OAAO,GAAG,CAAV,KAAgB,CAAhB,GACpB,IAAI,CAAC,iBAAL,CAAuB,aAAvB,CADoB,GAEpB,aAFJ;;AAIA,kBAAK,aAAa,GAAG,CAAhB,KAAsB,CAAtB,IAA2B,OAAO,GAAG,CAAV,KAAgB,CAA5C,IACC,aAAa,GAAG,CAAhB,KAAsB,CAAtB,IAA2B,OAAO,GAAG,CAAV,KAAgB,CADhD,EACoD;AAClD,gBAAA,QAAQ,kDACY,OAAO,GAAG,CADtB,gBAC6B,eAD7B,oEAG4B,QAH5B,wBAIJ,CAAC,GAAG,CAJA,uDAKK,CAAC,GAAG,CALT,8NASkB,QATlB,+CAUO,CAAC,GAAG,CAVX,iFAYK,CAAC,GAAG,CAZT,wDAAR,CADkD,CAiBlD;AACA;;AACA,oBAAI,aAAa,GAAG,CAApB,EAAuB;AACrB,kBAAA,QAAQ,wGAE4B,QAF5B,wBAGJ,CAHI,yDAIK,CAJL,6EAKK,CALL,4DAAR;AAQD;;AAED,gBAAA,QAAQ,oCACF,QAAQ,GAAG,CADT,4BAC4B,CAD5B,yBAC4C,CAAC,GAAG,CADhD,8BAAR;AAGD,eAlCD,MAkCO;AACL;AACA;AACA;AACA,oBAAI,eAAe,KAAK,CAAxB,EAA2B;AACzB,kBAAA,QAAQ,sCACF,QAAQ,GAAG,CADT,uBACuB,CADvB,4BAAR;AAGD,iBAJD,MAIO;AACL,kBAAA,QAAQ,oDACY,eADZ,sEAG4B,QAH5B,wBAIJ,CAAC,GAAG,CAJA,yDAKK,CAAC,GAAG,CALT,0FAMkB,QANlB,iDAOO,CAAC,GAAG,CAPX,qFASK,CAAC,GAAG,CATT,wEAYF,QAAQ,GAAG,CAZT,uBAYuB,CAAC,GAAG,CAZ3B,4BAAR;AAcD;AACF;AACF;AACF;AACF,SA3ID,MA2IO;AAAG;AACR,cAAI,CAAC,GAAG,WAAR,EAAqB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAI,OAAO,GAAG,CAAV,KAAgB,CAApB,EAAuB;AACrB,cAAA,QAAQ,oDACgB,WADhB,+DAE2B,QAF3B,wBAGJ,CAHI,qDAIK,CAJL,sNAOkB,QAPlB,6CAQO,CARP,6EAUK,CAVL,yFAauB,QAbvB,wBAcJ,CAAC,GAAG,CAdA,qDAeK,CAAC,GAAG,CAfT,8MAkBY,QAlBZ,6CAmBO,CAAC,GAAG,CAnBX,6EAqBK,CAAC,GAAG,CArBT,gEAwBF,QAxBE,4BAwBwB,CAxBxB,yBAwBwC,CAAC,GAAG,CAxB5C,0BAAR;;AA2BA,kBAAI,CAAC,GAAG,CAAJ,GAAQ,WAAZ,EAAyB;AACvB,gBAAA,QAAQ,4FAEgB,WAFhB,iEAG2B,QAH3B,uHAMF,QAAQ,GAAG,CANT,4BAM4B,CAAC,GAAG,CANhC,sCAAR;AAQD;AACF,aAtCD,MAsCO;AACL,cAAA,QAAQ,mDACe,QADf,wBACqC,CADrC,qDAEK,CAFL,0EAGY,QAHZ,6CAIO,CAJP,6EAMK,CANL,8EASY,WATZ,+DAU2B,QAV3B,wBAWJ,CAAC,GAAG,CAXA,qDAYK,CAAC,GAAG,CAZT,sFAakB,QAblB,6CAcO,CAAC,GAAG,CAdX,4EAgBK,CAAC,GAAG,CAhBT,gEAmBF,QAnBE,gDAoBK,CApBL,yBAoBqB,CAAC,GAAG,CApBzB,0BAAR;;AAuBA,kBAAI,CAAC,GAAG,CAAJ,GAAQ,WAAZ,EAAyB;AACvB,gBAAA,QAAQ,oCACF,QAAQ,GAAG,CADT,4BAC4B,CAD5B,yBAC4C,CAAC,GAAG,CADhD,4BAAR;AAGD;AACF;AACF;AACF,SAjO6D,CAmO9D;AACA;AACA;AACA;;;AACA,YAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B,UAAA,QAAQ,0CACU,CADV,eACgB,CADhB,iDAES,QAFT,+CAAR;;AAKA,cAAI,CAAC,GAAG,CAAJ,GAAQ,WAAZ,EAAyB;AACvB,YAAA,QAAQ,4CACU,CADV,eACgB,CAAC,GAAG,CADpB,mDAES,QAAQ,GAAG,CAFpB,iDAAR;AAID;AACF;AACF;;AACD,MAAA,QAAQ,yBAAR;AAGD;;AAED,QAAI,iBAAiB,GAAG,EAAxB;AAAA,QAA4B,sBAAsB,GAAG,EAArD;;AACA,QAAI,UAAJ,EAAgB;AACd,UAAI,kBAAJ,EAAwB;AACtB,QAAA,iBAAiB,8GAEb,UAFa,gBAAjB;AAID,OALD,MAKO,IAAI,iBAAJ,EAAuB;AAC5B,QAAA,iBAAiB,sGAEb,UAFa,gBAAjB;AAID,OALM,MAKA;AACL,QAAA,iBAAiB,kDACb,UADa,gBAAjB;AAGD;;AAED,MAAA,sBAAsB,iCAAtB;AACD;;AAED,UAAM,cAAc,GAAG,OAAO,GAAG,iCAAH,GAAuC,EAArE;;AACA,QAAI,OAAJ,EAAa;AACX,WAAK,aAAL,CAAmB,IAAnB,CAAwB,MAAxB;AACD;;AAED,QAAI,kBAAJ,EAAwB;AACtB,WAAK,aAAL,CAAmB,IAAnB,CAAwB,wBAAxB;AACD;;AACD,QAAI,iBAAJ,EAAuB;AACrB,WAAK,aAAL,CAAmB,IAAnB,CAAwB,gBAAxB;AACD;;AAED,SAAK,QAAL,qBACI,iBADJ,mDAGgC,YAHhC,eAGiD,WAHjD,gDAI6B,MAJ7B,eAIwC,OAJxC,6NAYoB,UAZpB,0CAawB,UAbxB,4OAoBM,QApBN,mFAuBM,cAvBN,uBAwBM,sBAxBN;AA4BD;;AA/WsC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {GPGPUProgram} from './gpgpu_math';\n\nexport class DepthwiseConvPacked2DProgram implements GPGPUProgram {\n  variableNames = ['x', 'W'];\n  packedInputs = true;\n  packedOutput = true;\n  outputShape: number[];\n  userCode: string;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: string = null, hasPreluActivation = false,\n      hasLeakyReluAlpha = false) {\n    this.outputShape = convInfo.outShape;\n    const channelMul = convInfo.outChannels / convInfo.inChannels;\n    const xNumRows = convInfo.inHeight;\n    const xNumCols = convInfo.inWidth;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const texelsAcross = filterWidth;\n\n    let mainLoop = `\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;`;\n\n    for (let c = 0; c < filterWidth; c++) {\n      mainLoop += `\n          vec4 xTexelC${c * 2};\n          int xTexelC${c * 2}Ready;\n          vec4 xC${c};`;\n    }\n\n    /**\n     * This vectorized implementation works by gathering the values needed for\n     * each output channel's dot product into vec4's and then multiplying them\n     * all together (this happens in the final double for-loop below). Most of\n     * the main loop consists of constructing these vec4's with the minimum\n     * number of texture2D calls, which means making use of all four returned\n     * values from a texture2D call at once.\n     */\n    for (let r = 0; r < filterHeight; r++) {\n      for (let c = 0; c < filterWidth; c++) {\n        mainLoop += `\n          xTexelC${c * 2} = vec4(0.0);\n          xTexelC${c * 2}Ready = 0;\n          xC${c} = vec4(0.0);`;\n      }\n      mainLoop += `\n        xR = xRCorner + ${r * dilationHeight};\n        if (xR >=0 && xR < ${xNumRows}) {\n      `;\n\n      for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n        const colIndex = texelC * 2;\n        const c = colIndex * dilationWidth;\n\n        mainLoop += `\n          xC = xCCorner + ${c};\n          `;\n\n        if (strideWidth === 1) {\n          if (colIndex < filterWidth) {\n            // If padding is odd, the outer texels have to be composed.\n            if (padLeft % 2 === 1) {\n              // TODO: Ensure vec4 previous does not result in redundant sample,\n              // and avoid setting xTexelRC's that exceed the boundary in the\n              // first place rather than resetting them to vec4(0)).\n\n              // To compute xCOffset:\n              // - If padding is odd, we must add 1 to ensure we ask for an\n              // even-numbered row.\n              // - We subtract 2 to access the previous texel.\n\n              mainLoop += `\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                  c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n              `;\n              // This texel has been read in previous iteration if the dilation\n              // is 1.\n              if (dilationWidth === 1 && c > 0) {\n                mainLoop += `\n                xC${colIndex} = vec4(xTexelC${c - 2}.zw, xTexelC${c}.xy);\n                `;\n              } else {\n                mainLoop += `\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < ${xNumCols}) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${xNumCols}) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${colIndex} = vec4(previous.zw, xTexelC${c}.xy);\n                  } else {\n                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${c}.xy);\n                  }\n                  `;\n              }\n            } else {\n              // Padding is even, so xRC corresponds to a single texel.\n              mainLoop += `\n                if (xC >= 0 && xC < ${xNumCols} && xTexelC${c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                xC${colIndex} = xTexelC${c};\n                `;\n            }\n\n            if (c + 1 < filterWidth) {\n              // If dilation is even, the second entry should match the first\n              // (either both are composed or both are single samples). But if\n              // dilation is odd, then the second entry should be the opposite\n              // of the first (if the first is composed, the second is a single\n              // sample, and vice versa.)\n\n              const nextTexelOffset = padLeft % 2 === 0 ?\n                  util.nearestLargerEven(dilationWidth) :\n                  dilationWidth;\n\n              if ((dilationWidth % 2 === 0 && padLeft % 2 === 1) ||\n                  (dilationWidth % 2 !== 0 && padLeft % 2 !== 1)) {\n                mainLoop += `\n                  xCOffset = xC + ${padLeft % 2} + ${nextTexelOffset};\n\n                  if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                    c + 2}Ready == 0) {\n                    xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${xNumCols}) {\n                      xTexelC${c + 2}.zw = vec2(0.0);\n                    }\n                    xTexelC${c + 2}Ready = 1;\n                  }\n                  `;\n\n                // If dilation > 1 then the xRC's will not be able to share any\n                // values, so each xRC will require two unique calls to getX.\n                if (dilationWidth > 1) {\n                  mainLoop += `\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                      c}Ready == 0) {\n                      xTexelC${c} = getX(batch, xR, xCOffset, d1);\n                      xTexelC${c}Ready = 1;\n                    }\n                    `;\n                }\n\n                mainLoop += `\n                  xC${colIndex + 1} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.xy);\n                  `;\n              } else {\n                // If dilation is 1 and padding is odd, we have already read the\n                // texel when constructing the previous x value. Here we can\n                // simply skip the texture read.\n                if (nextTexelOffset === 1) {\n                  mainLoop += `\n                    xC${colIndex + 1} = xTexelC${c};\n                    `;\n                } else {\n                  mainLoop += `\n                    xCOffset = xC + ${nextTexelOffset};\n\n                    if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                      c + 2}Ready == 0) {\n                      xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= ${xNumCols}) {\n                        xTexelC${c + 2}.zw = vec2(0.0);\n                      }\n                      xTexelC${c + 2}Ready = 1;\n                    }\n\n                    xC${colIndex + 1} = xTexelC${c + 2};\n                    `;\n                }\n              }\n            }\n          }\n        } else {  // stride === 2\n          if (c < filterWidth) {\n            // Depending on whether padLeft is even or odd, we want either the\n            // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n            // even, xC${colIndex +1} is simply the zw channels of texels we've\n            // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n            // need to come from the xy channels of a new texel, hence the `\n            // vec4\n            // final` initialized below.\n            if (padLeft % 2 === 1) {\n              mainLoop += `\n                xCOffset = xC + 1 - ${strideWidth};\n                if(xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                  c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ${xNumCols} && xTexelC${\n                  c + 2}Ready == 0) {\n                  xTexelC${c + 2} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= ${xNumCols}) {\n                    xTexelC${c + 2}.zw = vec2(0.0);\n                  }\n                  xTexelC${c + 2}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.zw);\n              `;\n\n              if (c + 1 < filterWidth) {\n                mainLoop += `\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + ${strideWidth};\n                  if(xCOffset >= 0 && xCOffset < ${xNumCols}) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${colIndex + 1} = vec4(xTexelC${c + 2}.xy, final.xy);\n                `;\n              }\n            } else {\n              mainLoop += `\n                if(xC >= 0 && xC < ${xNumCols} && xTexelC${c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                xCOffset = xC + ${strideWidth};\n                if(xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                  c + 2}Ready == 0) {\n                  xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c + 2}.zw = vec2(0.);\n                  }\n                  xTexelC${c + 2}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(\n                  xTexelC${c}.xy, xTexelC${c + 2}.xy);\n              `;\n\n              if (c + 1 < filterWidth) {\n                mainLoop += `\n                  xC${colIndex + 1} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.zw);\n                `;\n              }\n            }\n          }\n        }\n\n        // localize the dotProd accumulation within the loop, the theory is for\n        // GPU with limited cache, accumulate sum across large amount of\n        // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n        // 50 variables)\n        if (colIndex < filterWidth) {\n          mainLoop += `\n            wTexel = getW(${r}, ${c}, d1, q);\n            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);\n          `;\n\n          if (c + 1 < filterWidth) {\n            mainLoop += `\n              wTexel = getW(${r}, ${c + 1}, d1, q);\n              dotProd += xC${colIndex + 1} * vec4(wTexel.xz, wTexel.xz);\n            `;\n          }\n        }\n      }\n      mainLoop += `\n        }\n      `;\n    }\n\n    let activationSnippet = '', applyActivationSnippet = '';\n    if (activation) {\n      if (hasPreluActivation) {\n        activationSnippet = `vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`;\n      } else if (hasLeakyReluAlpha) {\n        activationSnippet = `vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`;\n      } else {\n        activationSnippet = `vec4 activation(vec4 x) {\n          ${activation}\n        }`;\n      }\n\n      applyActivationSnippet = `result = activation(result);`;\n    }\n\n    const addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n    if (hasLeakyReluAlpha) {\n      this.variableNames.push('leakyreluAlpha');\n    }\n\n    this.userCode = `\n      ${activationSnippet}\n\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${channelMul};\n        int q = d2 - d1 * ${channelMul};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${mainLoop}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `;\n  }\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}