{"ast":null,"code":"import _regeneratorRuntime from \"/Users/shouryagupta/Desktop/MS Engage 21/MSEngage21_VC/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/shouryagupta/Desktop/MS Engage 21/MSEngage21_VC/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\nimport * as util from '../util';\nimport { decodeWeights } from './io_utils';\nimport { monitorPromisesProgress } from './progress';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\n\nexport function loadWeightsAsArrayBuffer(_x, _x2) {\n  return _loadWeightsAsArrayBuffer.apply(this, arguments);\n}\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\n\nfunction _loadWeightsAsArrayBuffer() {\n  _loadWeightsAsArrayBuffer = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(fetchURLs, loadOptions) {\n    var fetchFunc, requests, fetchStartFraction, fetchEndFraction, responses, bufferPromises, bufferStartFraction, bufferEndFraction, buffers;\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) switch (_context2.prev = _context2.next) {\n        case 0:\n          if (loadOptions == null) {\n            loadOptions = {};\n          }\n\n          fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc; // Create the requests for all of the weights in parallel.\n\n          requests = fetchURLs.map(fetchURL => fetchFunc(fetchURL, loadOptions.requestInit, {\n            isBinary: true\n          }));\n          fetchStartFraction = 0;\n          fetchEndFraction = 0.5;\n\n          if (!(loadOptions.onProgress == null)) {\n            _context2.next = 11;\n            break;\n          }\n\n          _context2.next = 8;\n          return Promise.all(requests);\n\n        case 8:\n          _context2.t0 = _context2.sent;\n          _context2.next = 14;\n          break;\n\n        case 11:\n          _context2.next = 13;\n          return monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);\n\n        case 13:\n          _context2.t0 = _context2.sent;\n\n        case 14:\n          responses = _context2.t0;\n          bufferPromises = responses.map(response => response.arrayBuffer());\n          bufferStartFraction = 0.5;\n          bufferEndFraction = 1;\n\n          if (!(loadOptions.onProgress == null)) {\n            _context2.next = 24;\n            break;\n          }\n\n          _context2.next = 21;\n          return Promise.all(bufferPromises);\n\n        case 21:\n          _context2.t1 = _context2.sent;\n          _context2.next = 27;\n          break;\n\n        case 24:\n          _context2.next = 26;\n          return monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);\n\n        case 26:\n          _context2.t1 = _context2.sent;\n\n        case 27:\n          buffers = _context2.t1;\n          return _context2.abrupt(\"return\", buffers);\n\n        case 29:\n        case \"end\":\n          return _context2.stop();\n      }\n    }, _callee2);\n  }));\n  return _loadWeightsAsArrayBuffer.apply(this, arguments);\n}\n\nexport function loadWeights(_x3) {\n  return _loadWeights.apply(this, arguments);\n}\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\n\nfunction _loadWeights() {\n  _loadWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(manifest, filePathPrefix = '', weightNames, requestInit) {\n    var fetchWeights, loadWeights;\n    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n      while (1) switch (_context3.prev = _context3.next) {\n        case 0:\n          // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n          // single weight from a group, the whole group will be fetched. At a future\n          // date, we should support fetching only the individual shards within a\n          // group that are needed to reconstruct the requested weight.\n          // TODO(cais): Use `decodeWeights` for implementation.\n          fetchWeights = fetchUrls => loadWeightsAsArrayBuffer(fetchUrls, {\n            requestInit\n          });\n\n          loadWeights = weightsLoaderFactory(fetchWeights);\n          return _context3.abrupt(\"return\", loadWeights(manifest, filePathPrefix, weightNames));\n\n        case 3:\n        case \"end\":\n          return _context3.stop();\n      }\n    }, _callee3);\n  }));\n  return _loadWeights.apply(this, arguments);\n}\n\nexport function weightsLoaderFactory(fetchWeightsFunction) {\n  return /*#__PURE__*/function () {\n    var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(manifest, filePathPrefix = '', weightNames) {\n      var groupIndicesToFetchMap, groupWeightsToFetch, weightsFound, allManifestWeightNames, weightsNotFound, groupIndicesToFetch, fetchUrls, buffers, weightsTensorMap, bufferIndexOffset;\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) switch (_context.prev = _context.next) {\n          case 0:\n            // Collect all the groups, weights, and their relative offsets to be\n            // fetched.\n            groupIndicesToFetchMap = manifest.map(() => false);\n            groupWeightsToFetch = {};\n            weightsFound = weightNames != null ? weightNames.map(() => false) : [];\n            allManifestWeightNames = [];\n            manifest.forEach((manifestGroupConfig, groupIndex) => {\n              let groupOffset = 0;\n              manifestGroupConfig.weights.forEach(weightsEntry => {\n                const rawDtype = 'quantization' in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;\n                const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * util.sizeFromShape(weightsEntry.shape);\n\n                const enqueueWeightsForFetchingFn = () => {\n                  groupIndicesToFetchMap[groupIndex] = true;\n\n                  if (groupWeightsToFetch[groupIndex] == null) {\n                    groupWeightsToFetch[groupIndex] = [];\n                  }\n\n                  groupWeightsToFetch[groupIndex].push({\n                    manifestEntry: weightsEntry,\n                    groupOffset,\n                    sizeBytes: weightsBytes\n                  });\n                };\n\n                if (weightNames != null) {\n                  weightNames.forEach((weightName, weightIndex) => {\n                    if (weightName === weightsEntry.name) {\n                      enqueueWeightsForFetchingFn();\n                      weightsFound[weightIndex] = true;\n                    }\n                  });\n                } else {\n                  enqueueWeightsForFetchingFn();\n                }\n\n                allManifestWeightNames.push(weightsEntry.name);\n                groupOffset += weightsBytes;\n              });\n            });\n\n            if (weightsFound.every(found => found)) {\n              _context.next = 8;\n              break;\n            }\n\n            weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n            throw new Error(\"Could not find weights in manifest with names: \" + \"\".concat(weightsNotFound.join(', '), \". \\n\") + \"Manifest JSON has weights with names: \" + \"\".concat(allManifestWeightNames.join(', '), \".\"));\n\n          case 8:\n            // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n            // IDs.\n            groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n              if (shouldFetch) {\n                accumulator.push(i);\n              }\n\n              return accumulator;\n            }, []);\n            fetchUrls = [];\n            groupIndicesToFetch.forEach(i => {\n              manifest[i].paths.forEach(filepath => {\n                const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n                fetchUrls.push(fetchUrl);\n              });\n            });\n            _context.next = 13;\n            return fetchWeightsFunction(fetchUrls);\n\n          case 13:\n            buffers = _context.sent;\n            weightsTensorMap = {};\n            bufferIndexOffset = 0;\n            groupIndicesToFetch.forEach(i => {\n              const numBuffers = manifest[i].paths.length;\n              let groupBytes = 0;\n\n              for (let i = 0; i < numBuffers; i++) {\n                groupBytes += buffers[bufferIndexOffset + i].byteLength;\n              } // Create a buffer for the whole group.\n\n\n              const groupBuffer = new ArrayBuffer(groupBytes);\n              const groupByteBuffer = new Uint8Array(groupBuffer);\n              let groupBufferOffset = 0;\n\n              for (let i = 0; i < numBuffers; i++) {\n                const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n                groupByteBuffer.set(buffer, groupBufferOffset);\n                groupBufferOffset += buffer.byteLength;\n              }\n\n              const weightsEntries = groupWeightsToFetch[i];\n              weightsEntries.forEach(weightsEntry => {\n                const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n                const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n\n                for (const name in nameToTensorMap) {\n                  weightsTensorMap[name] = nameToTensorMap[name];\n                }\n              });\n              bufferIndexOffset += numBuffers;\n            });\n            return _context.abrupt(\"return\", weightsTensorMap);\n\n          case 18:\n          case \"end\":\n            return _context.stop();\n        }\n      }, _callee);\n    }));\n\n    return function (_x4) {\n      return _ref.apply(this, arguments);\n    };\n  }();\n}","map":{"version":3,"sources":["../../src/io/weights_loader.ts"],"names":[],"mappings":";;;AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,GAAR,QAAkB,gBAAlB;AAGA,OAAO,KAAK,IAAZ,MAAsB,SAAtB;AACA,SAAQ,aAAR,QAA4B,YAA5B;AACA,SAAQ,uBAAR,QAAsC,YAAtC;AACA,SAAQ,oBAAR,QAA6F,SAA7F;AAEA;;;;;;;;;;AAUG;;AACH,gBAAsB,wBAAtB;AAAA;AAAA;AAoCA;;;;;;;;AAQG;;;uFA5CI,kBACH,SADG,EACkB,WADlB;AAAA;AAAA;AAAA;AAAA;AAEL,cAAI,WAAW,IAAI,IAAnB,EAAyB;AACvB,YAAA,WAAW,GAAG,EAAd;AACD;;AAEK,UAAA,SAND,GAMa,WAAW,CAAC,SAAZ,IAAyB,IAAzB,GAAgC,GAAG,GAAG,QAAN,CAAe,KAA/C,GACgC,WAAW,CAAC,SAPzD,EASL;;AACM,UAAA,QAVD,GAUY,SAAS,CAAC,GAAV,CACb,QAAQ,IACJ,SAAS,CAAC,QAAD,EAAW,WAAW,CAAC,WAAvB,EAAoC;AAAC,YAAA,QAAQ,EAAE;AAAX,WAApC,CAFA,CAVZ;AAcC,UAAA,kBAdD,GAcsB,CAdtB;AAeC,UAAA,gBAfD,GAeoB,GAfpB;;AAAA,gBAiBa,WAAW,CAAC,UAAZ,IAA0B,IAjBvC;AAAA;AAAA;AAAA;;AAAA;AAAA,iBAkBK,OAAO,CAAC,GAAR,CAAY,QAAZ,CAlBL;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA,iBAmBK,uBAAuB,CACzB,QADyB,EACf,WAAW,CAAC,UADG,EACS,kBADT,EAEzB,gBAFyB,CAnB5B;;AAAA;AAAA;;AAAA;AAiBC,UAAA,SAjBD;AAuBC,UAAA,cAvBD,GAuBkB,SAAS,CAAC,GAAV,CAAc,QAAQ,IAAI,QAAQ,CAAC,WAAT,EAA1B,CAvBlB;AAyBC,UAAA,mBAzBD,GAyBuB,GAzBvB;AA0BC,UAAA,iBA1BD,GA0BqB,CA1BrB;;AAAA,gBA4BW,WAAW,CAAC,UAAZ,IAA0B,IA5BrC;AAAA;AAAA;AAAA;;AAAA;AAAA,iBA6BK,OAAO,CAAC,GAAR,CAAY,cAAZ,CA7BL;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA,iBA8BK,uBAAuB,CACzB,cADyB,EACT,WAAW,CAAC,UADH,EACe,mBADf,EAEzB,iBAFyB,CA9B5B;;AAAA;AAAA;;AAAA;AA4BC,UAAA,OA5BD;AAAA,4CAiCE,OAjCF;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AA6CP,gBAAsB,WAAtB;AAAA;AAAA;AAiBA;;;;;;;;;;;;;;;;;;;;;;;AAuBG;;;0EAxCI,kBACH,QADG,EAC8B,cAAc,GAAG,EAD/C,EAEH,WAFG,EAGH,WAHG;AAAA;AAAA;AAAA;AAAA;AAIL;AACA;AACA;AACA;AACA;AAEM,UAAA,YAVD,GAUiB,SAAD,IACjB,wBAAwB,CAAC,SAAD,EAAY;AAAC,YAAA;AAAD,WAAZ,CAXvB;;AAYC,UAAA,WAZD,GAYe,oBAAoB,CAAC,YAAD,CAZnC;AAAA,4CAcE,WAAW,CAAC,QAAD,EAAW,cAAX,EAA2B,WAA3B,CAdb;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AAyCP,OAAM,SAAU,oBAAV,CACF,oBADE,EACmE;AAGvE;AAAA,wEAAO,iBACI,QADJ,EACqC,cAAc,GAAG,EADtD,EAEI,WAFJ;AAAA;AAAA;AAAA;AAAA;AAGL;AACA;AACM,YAAA,sBALD,GAK0B,QAAQ,CAAC,GAAT,CAAa,MAAM,KAAnB,CAL1B;AAMC,YAAA,mBAND,GAWD,EAXC;AAYC,YAAA,YAZD,GAaD,WAAW,IAAI,IAAf,GAAsB,WAAW,CAAC,GAAZ,CAAgB,MAAM,KAAtB,CAAtB,GAAqD,EAbpD;AAcC,YAAA,sBAdD,GAcoC,EAdpC;AAeL,YAAA,QAAQ,CAAC,OAAT,CAAiB,CAAC,mBAAD,EAAsB,UAAtB,KAAoC;AACnD,kBAAI,WAAW,GAAG,CAAlB;AACA,cAAA,mBAAmB,CAAC,OAApB,CAA4B,OAA5B,CAAoC,YAAY,IAAG;AACjD,sBAAM,QAAQ,GAAI,kBAAkB,YAAnB,GACb,YAAY,CAAC,YAAb,CAA0B,KADb,GAEb,YAAY,CAAC,KAFjB;AAIA,sBAAM,YAAY,GAAG,oBAAoB,CAAC,QAAD,CAApB,GACjB,IAAI,CAAC,aAAL,CAAmB,YAAY,CAAC,KAAhC,CADJ;;AAGA,sBAAM,2BAA2B,GAAG,MAAK;AACvC,kBAAA,sBAAsB,CAAC,UAAD,CAAtB,GAAqC,IAArC;;AACA,sBAAI,mBAAmB,CAAC,UAAD,CAAnB,IAAmC,IAAvC,EAA6C;AAC3C,oBAAA,mBAAmB,CAAC,UAAD,CAAnB,GAAkC,EAAlC;AACD;;AAED,kBAAA,mBAAmB,CAAC,UAAD,CAAnB,CAAgC,IAAhC,CAAqC;AACnC,oBAAA,aAAa,EAAE,YADoB;AAEnC,oBAAA,WAFmC;AAGnC,oBAAA,SAAS,EAAE;AAHwB,mBAArC;AAKD,iBAXD;;AAaA,oBAAI,WAAW,IAAI,IAAnB,EAAyB;AACvB,kBAAA,WAAW,CAAC,OAAZ,CAAoB,CAAC,UAAD,EAAa,WAAb,KAA4B;AAC9C,wBAAI,UAAU,KAAK,YAAY,CAAC,IAAhC,EAAsC;AACpC,sBAAA,2BAA2B;AAC3B,sBAAA,YAAY,CAAC,WAAD,CAAZ,GAA4B,IAA5B;AACD;AACF,mBALD;AAMD,iBAPD,MAOO;AACL,kBAAA,2BAA2B;AAC5B;;AAED,gBAAA,sBAAsB,CAAC,IAAvB,CAA4B,YAAY,CAAC,IAAzC;AACA,gBAAA,WAAW,IAAI,YAAf;AACD,eAlCD;AAmCD,aArCD;;AAfK,gBAsDA,YAAY,CAAC,KAAb,CAAmB,KAAK,IAAI,KAA5B,CAtDA;AAAA;AAAA;AAAA;;AAuDG,YAAA,eAvDH,GAuDqB,WAAW,CAAC,MAAZ,CAAmB,CAAC,CAAD,EAAI,CAAJ,KAAU,CAAC,YAAY,CAAC,CAAD,CAA1C,CAvDrB;AAAA,kBAwDG,IAAI,KAAJ,CACF,8DACG,eAAe,CAAC,IAAhB,CAAqB,IAArB,CADH,iEAGG,sBAAsB,CAAC,IAAvB,CAA4B,IAA5B,CAHH,MADE,CAxDH;;AAAA;AA+DL;AACA;AACM,YAAA,mBAjED,GAkED,sBAAsB,CAAC,MAAvB,CAA8B,CAAC,WAAD,EAAc,WAAd,EAA2B,CAA3B,KAAgC;AAC5D,kBAAI,WAAJ,EAAiB;AACf,gBAAA,WAAW,CAAC,IAAZ,CAAiB,CAAjB;AACD;;AACD,qBAAO,WAAP;AACD,aALD,EAKG,EALH,CAlEC;AAyEC,YAAA,SAzED,GAyEuB,EAzEvB;AA0EL,YAAA,mBAAmB,CAAC,OAApB,CAA4B,CAAC,IAAG;AAC9B,cAAA,QAAQ,CAAC,CAAD,CAAR,CAAY,KAAZ,CAAkB,OAAlB,CAA0B,QAAQ,IAAG;AACnC,sBAAM,QAAQ,GAAG,cAAc,IAC1B,CAAC,cAAc,CAAC,QAAf,CAAwB,GAAxB,CAAD,GAAgC,GAAhC,GAAsC,EADZ,CAAd,GACgC,QADjD;AAEA,gBAAA,SAAS,CAAC,IAAV,CAAe,QAAf;AACD,eAJD;AAKD,aAND;AA1EK;AAAA,mBAiFiB,oBAAoB,CAAC,SAAD,CAjFrC;;AAAA;AAiFC,YAAA,OAjFD;AAmFC,YAAA,gBAnFD,GAmFoC,EAnFpC;AAoFD,YAAA,iBApFC,GAoFmB,CApFnB;AAqFL,YAAA,mBAAmB,CAAC,OAApB,CAA4B,CAAC,IAAG;AAC9B,oBAAM,UAAU,GAAG,QAAQ,CAAC,CAAD,CAAR,CAAY,KAAZ,CAAkB,MAArC;AAEA,kBAAI,UAAU,GAAG,CAAjB;;AACA,mBAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAApB,EAAgC,CAAC,EAAjC,EAAqC;AACnC,gBAAA,UAAU,IAAI,OAAO,CAAC,iBAAiB,GAAG,CAArB,CAAP,CAA+B,UAA7C;AACD,eAN6B,CAQ9B;;;AACA,oBAAM,WAAW,GAAG,IAAI,WAAJ,CAAgB,UAAhB,CAApB;AACA,oBAAM,eAAe,GAAG,IAAI,UAAJ,CAAe,WAAf,CAAxB;AACA,kBAAI,iBAAiB,GAAG,CAAxB;;AACA,mBAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAApB,EAAgC,CAAC,EAAjC,EAAqC;AACnC,sBAAM,MAAM,GAAG,IAAI,UAAJ,CAAe,OAAO,CAAC,iBAAiB,GAAG,CAArB,CAAtB,CAAf;AACA,gBAAA,eAAe,CAAC,GAAhB,CAAoB,MAApB,EAA4B,iBAA5B;AACA,gBAAA,iBAAiB,IAAI,MAAM,CAAC,UAA5B;AACD;;AAED,oBAAM,cAAc,GAAG,mBAAmB,CAAC,CAAD,CAA1C;AACA,cAAA,cAAc,CAAC,OAAf,CAAuB,YAAY,IAAG;AACpC,sBAAM,UAAU,GAAG,WAAW,CAAC,KAAZ,CACf,YAAY,CAAC,WADE,EAEf,YAAY,CAAC,WAAb,GAA2B,YAAY,CAAC,SAFzB,CAAnB;AAGA,sBAAM,eAAe,GACjB,aAAa,CAAC,UAAD,EAAa,CAAC,YAAY,CAAC,aAAd,CAAb,CADjB;;AAEA,qBAAK,MAAM,IAAX,IAAmB,eAAnB,EAAoC;AAClC,kBAAA,gBAAgB,CAAC,IAAD,CAAhB,GAAyB,eAAe,CAAC,IAAD,CAAxC;AACD;AACF,eATD;AAWA,cAAA,iBAAiB,IAAI,UAArB;AACD,aA/BD;AArFK,6CAsHE,gBAtHF;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAP;;AAAA;AAAA;AAAA;AAAA;AAwHD","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '../environment';\n\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\nimport {decodeWeights} from './io_utils';\nimport {monitorPromisesProgress} from './progress';\nimport {DTYPE_VALUE_SIZE_MAP, LoadOptions, WeightsManifestConfig, WeightsManifestEntry} from './types';\n\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(\n    fetchURLs: string[], loadOptions?: LoadOptions): Promise<ArrayBuffer[]> {\n  if (loadOptions == null) {\n    loadOptions = {};\n  }\n\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n                                                    loadOptions.fetchFunc;\n\n  // Create the requests for all of the weights in parallel.\n  const requests = fetchURLs.map(\n      fetchURL =>\n          fetchFunc(fetchURL, loadOptions.requestInit, {isBinary: true}));\n\n  const fetchStartFraction = 0;\n  const fetchEndFraction = 0.5;\n\n  const responses = loadOptions.onProgress == null ?\n      await Promise.all(requests) :\n      await monitorPromisesProgress(\n          requests, loadOptions.onProgress, fetchStartFraction,\n          fetchEndFraction);\n\n  const bufferPromises = responses.map(response => response.arrayBuffer());\n\n  const bufferStartFraction = 0.5;\n  const bufferEndFraction = 1;\n\n  const buffers = loadOptions.onProgress == null ?\n      await Promise.all(bufferPromises) :\n      await monitorPromisesProgress(\n          bufferPromises, loadOptions.onProgress, bufferStartFraction,\n          bufferEndFraction);\n  return buffers;\n}\n\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(\n    manifest: WeightsManifestConfig, filePathPrefix = '',\n    weightNames?: string[],\n    requestInit?: RequestInit): Promise<NamedTensorMap> {\n  // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n  // single weight from a group, the whole group will be fetched. At a future\n  // date, we should support fetching only the individual shards within a\n  // group that are needed to reconstruct the requested weight.\n  // TODO(cais): Use `decodeWeights` for implementation.\n\n  const fetchWeights = (fetchUrls: string[]) =>\n      loadWeightsAsArrayBuffer(fetchUrls, {requestInit});\n  const loadWeights = weightsLoaderFactory(fetchWeights);\n\n  return loadWeights(manifest, filePathPrefix, weightNames);\n}\n\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(\n    fetchWeightsFunction: (fetchUrls: string[]) => Promise<ArrayBuffer[]>):\n    (manifest: WeightsManifestConfig, filePathPrefix?: string,\n     weightNames?: string[]) => Promise<NamedTensorMap> {\n  return async(\n             manifest: WeightsManifestConfig, filePathPrefix = '',\n             weightNames?: string[]): Promise<NamedTensorMap> => {\n    // Collect all the groups, weights, and their relative offsets to be\n    // fetched.\n    const groupIndicesToFetchMap = manifest.map(() => false);\n    const groupWeightsToFetch: {\n      [group: number]: Array<{\n        manifestEntry: WeightsManifestEntry; groupOffset: number;\n        sizeBytes: number;\n      }>\n    } = {};\n    const weightsFound =\n        weightNames != null ? weightNames.map(() => false) : [];\n    const allManifestWeightNames: string[] = [];\n    manifest.forEach((manifestGroupConfig, groupIndex) => {\n      let groupOffset = 0;\n      manifestGroupConfig.weights.forEach(weightsEntry => {\n        const rawDtype = ('quantization' in weightsEntry) ?\n            weightsEntry.quantization.dtype :\n            weightsEntry.dtype;\n\n        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] *\n            util.sizeFromShape(weightsEntry.shape);\n\n        const enqueueWeightsForFetchingFn = () => {\n          groupIndicesToFetchMap[groupIndex] = true;\n          if (groupWeightsToFetch[groupIndex] == null) {\n            groupWeightsToFetch[groupIndex] = [];\n          }\n\n          groupWeightsToFetch[groupIndex].push({\n            manifestEntry: weightsEntry,\n            groupOffset,\n            sizeBytes: weightsBytes\n          });\n        };\n\n        if (weightNames != null) {\n          weightNames.forEach((weightName, weightIndex) => {\n            if (weightName === weightsEntry.name) {\n              enqueueWeightsForFetchingFn();\n              weightsFound[weightIndex] = true;\n            }\n          });\n        } else {\n          enqueueWeightsForFetchingFn();\n        }\n\n        allManifestWeightNames.push(weightsEntry.name);\n        groupOffset += weightsBytes;\n      });\n    });\n\n    if (!weightsFound.every(found => found)) {\n      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n      throw new Error(\n          `Could not find weights in manifest with names: ` +\n          `${weightsNotFound.join(', ')}. \\n` +\n          `Manifest JSON has weights with names: ` +\n          `${allManifestWeightNames.join(', ')}.`);\n    }\n\n    // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n    // IDs.\n    const groupIndicesToFetch =\n        groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n          if (shouldFetch) {\n            accumulator.push(i);\n          }\n          return accumulator;\n        }, []);\n\n    const fetchUrls: string[] = [];\n    groupIndicesToFetch.forEach(i => {\n      manifest[i].paths.forEach(filepath => {\n        const fetchUrl = filePathPrefix +\n            (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n        fetchUrls.push(fetchUrl);\n      });\n    });\n    const buffers = await fetchWeightsFunction(fetchUrls);\n\n    const weightsTensorMap: NamedTensorMap = {};\n    let bufferIndexOffset = 0;\n    groupIndicesToFetch.forEach(i => {\n      const numBuffers = manifest[i].paths.length;\n\n      let groupBytes = 0;\n      for (let i = 0; i < numBuffers; i++) {\n        groupBytes += buffers[bufferIndexOffset + i].byteLength;\n      }\n\n      // Create a buffer for the whole group.\n      const groupBuffer = new ArrayBuffer(groupBytes);\n      const groupByteBuffer = new Uint8Array(groupBuffer);\n      let groupBufferOffset = 0;\n      for (let i = 0; i < numBuffers; i++) {\n        const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n        groupByteBuffer.set(buffer, groupBufferOffset);\n        groupBufferOffset += buffer.byteLength;\n      }\n\n      const weightsEntries = groupWeightsToFetch[i];\n      weightsEntries.forEach(weightsEntry => {\n        const byteBuffer = groupBuffer.slice(\n            weightsEntry.groupOffset,\n            weightsEntry.groupOffset + weightsEntry.sizeBytes);\n        const nameToTensorMap =\n            decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n        for (const name in nameToTensorMap) {\n          weightsTensorMap[name] = nameToTensorMap[name];\n        }\n      });\n\n      bufferIndexOffset += numBuffers;\n    });\n\n    return weightsTensorMap;\n  };\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}